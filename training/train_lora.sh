python training/train_lora.py \
  --model_name "/data/hector/models/mistral-7b-instruct" \
  --dataset_name "/home/hector/Ads/datasets/processed_dpo_dataset.json" \
  --output_dir "/data/hector/models/mistral-7b-instruct-ultra-safe-dpo-more-epochs" \
  --batch_size 4 \
  --num_epochs 5 \
  --learning_rate 1e-6 \
  --beta 0.65 \
  --lora_rank 16 \
  --lora_alpha 16 \
  --lora_dropout 0.15 \
  --save_strategy "no" \
  --save_steps 100 \
  --eval_steps 100