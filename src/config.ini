[server]
hostname = 0.0.0.0
port = 8888

[model]
path = /data/hector/models/mistral-7b-gguf/mistral-7b-v0.1.Q4_K_M.gguf
max_tokens = 2048
gpu_device = 3
# For llama-cpp-python: -1 = all GPUs, 0+ = specific GPU index

[embedding]
path = /data/hector/models/stella-en-1.5B
gpu_device = 2
# For SentenceTransformers: cuda:0, cuda:1, etc., or cpu